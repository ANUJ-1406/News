{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e7f24e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Converting timestamps...\n",
      "Creating user and news mappings...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, log_loss\n",
    "import pickle\n",
    "from collections import defaultdict, deque\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import csr_matrix\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "TIME_WINDOW=3*24 * 60 * 60\n",
    "ALPHA=0.9\n",
    "# Load data\n",
    "print(\"Loading datasets...\")\n",
    "news_train = pd.read_csv(\"/Users/anuj/Downloads/MINDsmall_train/news.tsv\", sep='\\t', header=None,\n",
    "                          names=['NewsID', 'Category', 'SubCategory', 'Title', 'Abstract', 'URL', 'TitleEntities', 'AbstractEntities'])\n",
    "behaviors_train = pd.read_csv(\"/Users/anuj/Downloads/MINDsmall_train/behaviors.tsv\", sep='\\t', header=None,\n",
    "                              names=['ImpressionID', 'UserID', 'Time', 'History', 'Impressions'])\n",
    "news_dev = pd.read_csv(\"/Users/anuj/Downloads/MINDsmall_dev/news.tsv\", sep='\\t', header=None,\n",
    "                          names=['NewsID', 'Category', 'SubCategory', 'Title', 'Abstract', 'URL', 'TitleEntities', 'AbstractEntities'])\n",
    "valid_behaviors = pd.read_csv(\"/Users/anuj/Downloads/MINDsmall_dev/behaviors.tsv\", sep='\\t', header=None,\n",
    "                              names=['ImpressionID', 'UserID', 'Time', 'History', 'Impressions'])\n",
    "\n",
    "print(\"Converting timestamps...\")\n",
    "# Convert timestamp to numeric seconds\n",
    "behaviors_train['Timestamp'] = pd.to_datetime(behaviors_train['Time']).astype(int) // 10**9\n",
    "valid_behaviors['Timestamp'] = pd.to_datetime(valid_behaviors['Time']).astype(int) // 10**9\n",
    "\n",
    "# Create user and news indices mapping\n",
    "print(\"Creating user and news mappings...\")\n",
    "users = list(set(behaviors_train['UserID'].tolist() + valid_behaviors['UserID'].tolist()))\n",
    "news_items = list(set(news_train['NewsID'].tolist() + news_dev['NewsID'].tolist()))\n",
    "first_valid_time = valid_behaviors.iloc[0]['Timestamp']\n",
    "train_behaviors = behaviors_train[(behaviors_train['Timestamp'] >= first_valid_time - TIME_WINDOW) &\n",
    "                                  (behaviors_train['Timestamp'] < first_valid_time)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "757abaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load user profiles\n",
    "with open('/Users/anuj/Desktop/Recommender_G3P2/Baseline/ctr_global.pkl', 'rb') as f:\n",
    "    ctr_global = pickle.load(f)\n",
    "    \n",
    "with open('/Users/anuj/Desktop/Recommender_G3P2/Baseline/time_aware_ctr.pkl', 'rb') as f:\n",
    "    time_aware_ctr = pickle.load(f)\n",
    "\n",
    "with open('/Users/anuj/Desktop/Recommender_G3P2/Content_based/tfidf_vectorizer.pkl', 'rb') as f:\n",
    "    tfidf_vectorizer = pickle.load(f)\n",
    "\n",
    "# Load user profiles\n",
    "with open('/Users/anuj/Desktop/Recommender_G3P2/Content_based/user_profiles.pkl', 'rb') as f:\n",
    "    user_profiles = pickle.load(f)\n",
    "\n",
    "# Load TF-IDF matrix\n",
    "with open('/Users/anuj/Desktop/Recommender_G3P2/Content_based/tfidf_matrix.pkl', 'rb') as f:\n",
    "    tfidf_matrix = pickle.load(f)\n",
    "\n",
    "# Load news_id_to_index\n",
    "with open('/Users/anuj/Desktop/Recommender_G3P2/Content_based/news_id_to_index.pkl', 'rb') as f:\n",
    "    news_id_to_index = pickle.load(f)\n",
    "\n",
    "with open('/Users/anuj/Desktop/Recommender_G3P2/Collaborative/model_fm.pkl', 'rb') as f:\n",
    "    model_fm = pickle.load(f)\n",
    "\n",
    "with open('/Users/anuj/Desktop/Recommender_G3P2/Collaborative/user2idx.pkl', 'rb') as f:\n",
    "    user2idx = pickle.load(f)\n",
    "\n",
    "with open('/Users/anuj/Desktop/Recommender_G3P2/Collaborative/news2idx.pkl', 'rb') as f:\n",
    "    news2idx = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66b6cb8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training hybrid model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing training data: 100%|██████████| 156965/156965 [16:58<00:00, 154.08it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================\n",
    "# 4. Train Hybrid Model with Logistic Regression\n",
    "# ============================\n",
    "print(\"Training hybrid model...\")\n",
    "X, y = [], []\n",
    "news_stats = defaultdict(lambda: {'clicks': deque(), 'impressions': deque()})\n",
    "\n",
    "for row in tqdm(behaviors_train.itertuples(), total=len(behaviors_train), desc=\"Preparing training data\"):\n",
    "    uid = row.UserID\n",
    "    if uid not in user2idx:\n",
    "        continue\n",
    "    uid_idx = user2idx[uid]\n",
    "\n",
    "    impressions = row.Impressions.split()\n",
    "    for imp in impressions:\n",
    "        if '-' not in imp:\n",
    "            continue\n",
    "            \n",
    "        nid, label = imp.split('-')\n",
    "        label = int(label)\n",
    "        news_stats[nid]['impressions'].append(row.Timestamp)\n",
    "        if label == '1':\n",
    "            news_stats[nid]['clicks'].append(row.Timestamp)\n",
    "        # CTR model score\n",
    "        global_ctr = ctr_global.get(nid, 0.0)\n",
    "        time_ctr = time_aware_ctr.get(nid, 0.0)\n",
    "        score_ctr = ALPHA * time_ctr + (1 - ALPHA) * global_ctr\n",
    "        \n",
    "        # CBF model score\n",
    "        if uid in user_profiles and nid in news_id_to_index:\n",
    "            user_vector = user_profiles[uid].reshape(1, -1)\n",
    "            news_vector = tfidf_matrix[news_id_to_index[nid]]\n",
    "            score_cbf = cosine_similarity(user_vector, news_vector)[0][0]\n",
    "        else:\n",
    "            score_cbf = 0.0\n",
    "\n",
    "        # CF model score\n",
    "        if nid in news2idx:\n",
    "            nid_idx = news2idx[nid]\n",
    "            score_cf = np.dot(model_fm.get_user_representations()[0][uid_idx], \n",
    "                  model_fm.get_item_representations()[0][nid_idx])\n",
    "\n",
    "        else:\n",
    "            score_cf = 0.0\n",
    "\n",
    "        X.append([score_ctr, score_cbf, score_cf])\n",
    "        y.append(label)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9059e6c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting decision tree classifier...\n",
      "Decision Tree Feature Importances: [0.36226688 0.60984655 0.02788658]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Fitting decision tree classifier...\")\n",
    "# You can adjust these hyperparameters based on your needs\n",
    "tree_model = DecisionTreeClassifier(\n",
    "    max_depth=5,              # Prevents overfitting\n",
    "    min_samples_split=20,     # Minimum samples required to split a node\n",
    "    min_samples_leaf=10,      # Minimum samples required at a leaf node\n",
    "    class_weight='balanced'   # Handle class imbalance\n",
    ")\n",
    "tree_model.fit(X, y)\n",
    "\n",
    "# Print feature importances instead of coefficients\n",
    "print(\"Decision Tree Feature Importances:\", tree_model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "caa9cbb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing training data: 100%|██████████| 156965/156965 [00:01<00:00, 88814.52it/s]\n"
     ]
    }
   ],
   "source": [
    "data = np.load(\"hybrid_data.npz\")\n",
    "X = data[\"X\"]\n",
    "y = data[\"y\"]\n",
    "with open(\"scaler.pkl\", \"rb\") as f:\n",
    "    scaler = pickle.load(f)\n",
    "news_stats = defaultdict(lambda: {'clicks': deque(), 'impressions': deque()})\n",
    "\n",
    "for row in tqdm(behaviors_train.itertuples(), total=len(behaviors_train), desc=\"Preparing training data\"):\n",
    "    uid = row.UserID\n",
    "    if uid not in user2idx:\n",
    "        continue\n",
    "    uid_idx = user2idx[uid]\n",
    "\n",
    "    impressions = row.Impressions.split()\n",
    "    for imp in impressions:\n",
    "        if '-' not in imp:\n",
    "            continue\n",
    "            \n",
    "        nid, label = imp.split('-')\n",
    "        label = int(label)\n",
    "        news_stats[nid]['impressions'].append(row.Timestamp)\n",
    "        if label == '1':\n",
    "            news_stats[nid]['clicks'].append(row.Timestamp)\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86371b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating hybrid model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 73152/73152 [01:45<00:00, 693.70it/s] \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================\n",
    "# 5. Evaluate Hybrid Model\n",
    "# ============================\n",
    "print(\"Evaluating hybrid model...\")\n",
    "all_labels, all_scores = [], []\n",
    "\n",
    "def update_rolling_stats(current_time):\n",
    "    for nid in list(news_stats.keys()):\n",
    "        while news_stats[nid]['clicks'] and news_stats[nid]['clicks'][0] < current_time - TIME_WINDOW:\n",
    "            news_stats[nid]['clicks'].popleft()\n",
    "        while news_stats[nid]['impressions'] and news_stats[nid]['impressions'][0] < current_time - TIME_WINDOW:\n",
    "            news_stats[nid]['impressions'].popleft()\n",
    "        if not news_stats[nid]['clicks'] and not news_stats[nid]['impressions']:\n",
    "            del news_stats[nid]\n",
    "\n",
    "\n",
    "for row in tqdm(valid_behaviors.itertuples(), total=len(valid_behaviors), desc=\"Evaluating\"):\n",
    "    uid = row.UserID\n",
    "    if uid not in user2idx:\n",
    "        continue\n",
    "    uid_idx = user2idx[uid]\n",
    "    current_time = row.Timestamp\n",
    "    update_rolling_stats(current_time)\n",
    "    labels, scores = [], []\n",
    "\n",
    "    impressions = row.Impressions.split()\n",
    "    for imp in impressions:\n",
    "        if '-' not in imp:\n",
    "            continue\n",
    "            \n",
    "        nid, label = imp.split('-')\n",
    "        labels.append(int(label))\n",
    "\n",
    "        global_ctr = ctr_global.get(nid, 0.0)\n",
    "        time_ctr = time_aware_ctr.get(nid, 0.0)\n",
    "        score_ctr = ALPHA * time_ctr + (1 - ALPHA) * global_ctr        \n",
    "        if uid in user_profiles and nid in news_id_to_index:\n",
    "            user_vector = user_profiles[uid].reshape(1, -1)\n",
    "            news_vector = tfidf_matrix[news_id_to_index[nid]]\n",
    "            score_cbf = cosine_similarity(user_vector, news_vector)[0][0]\n",
    "        else:\n",
    "            score_cbf = 0.0\n",
    "        if nid in news2idx:\n",
    "            nid_idx = news2idx[nid]\n",
    "            score_cf = np.dot(model_fm.get_user_representations()[0][uid_idx], \n",
    "                  model_fm.get_item_representations()[0][nid_idx])\n",
    "\n",
    "        else:\n",
    "            score_cf = 0.0\n",
    "\n",
    "        features = np.array([score_ctr, score_cbf, score_cf]).reshape(1, -1)\n",
    "        features_scaled = scaler.transform(features)  # Make sure to scale new features too\n",
    "        prob = tree_model.predict_proba(features_scaled)[0][1]\n",
    "        scores.append(prob)\n",
    "        news_stats[nid]['impressions'].append(current_time)\n",
    "        if label == '1':\n",
    "            news_stats[nid]['clicks'].append(current_time)\n",
    "\n",
    "    if scores and len(set(labels)) > 1:\n",
    "        all_labels.append(labels)\n",
    "        all_scores.append(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3fbe447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Hybrid Model Evaluation ---\n",
      "AUC: 0.6773\n",
      "MRR: 0.3836\n",
      "nDCG@5: 0.3678\n",
      "nDCG@10: 0.4275\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define evaluation metrics\n",
    "def mrr_score(labels, scores):\n",
    "    order = np.argsort(scores)[::-1]\n",
    "    labels = np.array(labels)[order]\n",
    "    for idx, label in enumerate(labels):\n",
    "        if label == 1:\n",
    "            return 1.0 / (idx + 1)\n",
    "    return 0.0\n",
    "\n",
    "def dcg_score(labels, scores, k):\n",
    "    order = np.argsort(scores)[::-1][:k]\n",
    "    gains = np.array(labels)[order]\n",
    "    discounts = np.log2(np.arange(2, len(gains) + 2))\n",
    "    return np.sum(gains / discounts)\n",
    "\n",
    "def ndcg_score(labels, scores, k):\n",
    "    dcg = dcg_score(labels, scores, k)\n",
    "    ideal_dcg = dcg_score(labels, labels, k)\n",
    "    return dcg / ideal_dcg if ideal_dcg > 0 else 0.0\n",
    "\n",
    "# Compute final metrics\n",
    "mrr, ndcg5, ndcg10, auc = [], [], [], []\n",
    "\n",
    "for labels, scores in zip(all_labels, all_scores):\n",
    "    if len(set(labels)) > 1:  # Need both positive and negative examples for AUC\n",
    "        auc.append(roc_auc_score(labels, scores))\n",
    "    mrr.append(mrr_score(labels, scores))\n",
    "    ndcg5.append(ndcg_score(labels, scores, 5))\n",
    "    ndcg10.append(ndcg_score(labels, scores, 10))\n",
    "\n",
    "print(\"\\n--- Hybrid Model Evaluation ---\")\n",
    "print(f\"AUC: {np.mean(auc):.4f}\")\n",
    "print(f\"MRR: {np.mean(mrr):.4f}\")\n",
    "print(f\"nDCG@5: {np.mean(ndcg5):.4f}\")\n",
    "print(f\"nDCG@10: {np.mean(ndcg10):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7bc32b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the decision tree model\n",
    "with open('hybrid_tree_model.pkl', 'wb') as f:\n",
    "    pickle.dump(tree_model, f)\n",
    "\n",
    "# Also save the scaler for future use\n",
    "with open('hybrid_tree_scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67431d3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
