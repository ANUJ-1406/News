{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "450828f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Converting timestamps...\n",
      "Creating user and news mappings...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, log_loss\n",
    "import pickle\n",
    "from collections import defaultdict, deque\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import csr_matrix\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "TIME_WINDOW=2*24 * 60 * 60\n",
    "ALPHA=0.9\n",
    "# Load data\n",
    "print(\"Loading datasets...\")\n",
    "news_train = pd.read_csv(\"/Users/anuj/Downloads/MINDsmall_train/news.tsv\", sep='\\t', header=None,\n",
    "                          names=['NewsID', 'Category', 'SubCategory', 'Title', 'Abstract', 'URL', 'TitleEntities', 'AbstractEntities'])\n",
    "behaviors_train = pd.read_csv(\"/Users/anuj/Downloads/MINDsmall_train/behaviors.tsv\", sep='\\t', header=None,\n",
    "                              names=['ImpressionID', 'UserID', 'Time', 'History', 'Impressions'])\n",
    "news_dev = pd.read_csv(\"/Users/anuj/Downloads/MINDsmall_dev/news.tsv\", sep='\\t', header=None,\n",
    "                          names=['NewsID', 'Category', 'SubCategory', 'Title', 'Abstract', 'URL', 'TitleEntities', 'AbstractEntities'])\n",
    "valid_behaviors = pd.read_csv(\"/Users/anuj/Downloads/MINDsmall_dev/behaviors.tsv\", sep='\\t', header=None,\n",
    "                              names=['ImpressionID', 'UserID', 'Time', 'History', 'Impressions'])\n",
    "\n",
    "print(\"Converting timestamps...\")\n",
    "# Convert timestamp to numeric seconds\n",
    "behaviors_train['Timestamp'] = pd.to_datetime(behaviors_train['Time']).astype(int) // 10**9\n",
    "valid_behaviors['Timestamp'] = pd.to_datetime(valid_behaviors['Time']).astype(int) // 10**9\n",
    "\n",
    "# Create user and news indices mapping\n",
    "print(\"Creating user and news mappings...\")\n",
    "users = list(set(behaviors_train['UserID'].tolist() + valid_behaviors['UserID'].tolist()))\n",
    "news_items = list(set(news_train['NewsID'].tolist() + news_dev['NewsID'].tolist()))\n",
    "first_valid_time = valid_behaviors.iloc[0]['Timestamp']\n",
    "train_behaviors = behaviors_train[(behaviors_train['Timestamp'] >= first_valid_time - TIME_WINDOW) &\n",
    "                                  (behaviors_train['Timestamp'] < first_valid_time)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49c7be11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anuj/.pyenv/versions/3.11.9/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load user profiles\n",
    "with open('/Users/anuj/Desktop/Recommender_G3P2/Baseline/ctr_global.pkl', 'rb') as f:\n",
    "    ctr_global = pickle.load(f)\n",
    "    \n",
    "with open('/Users/anuj/Desktop/Recommender_G3P2/Baseline/time_aware_ctr.pkl', 'rb') as f:\n",
    "    time_aware_ctr = pickle.load(f)\n",
    "\n",
    "with open('/Users/anuj/Desktop/Recommender_G3P2/Content_based/tfidf_vectorizer.pkl', 'rb') as f:\n",
    "    tfidf_vectorizer = pickle.load(f)\n",
    "\n",
    "# Load user profiles\n",
    "with open('/Users/anuj/Desktop/Recommender_G3P2/Content_based/user_profiles.pkl', 'rb') as f:\n",
    "    user_profiles = pickle.load(f)\n",
    "\n",
    "# Load TF-IDF matrix\n",
    "with open('/Users/anuj/Desktop/Recommender_G3P2/Content_based/tfidf_matrix.pkl', 'rb') as f:\n",
    "    tfidf_matrix = pickle.load(f)\n",
    "\n",
    "# Load news_id_to_index\n",
    "with open('/Users/anuj/Desktop/Recommender_G3P2/Content_based/news_id_to_index.pkl', 'rb') as f:\n",
    "    news_id_to_index = pickle.load(f)\n",
    "\n",
    "with open('/Users/anuj/Desktop/Recommender_G3P2/Collaborative/model_bpr.pkl', 'rb') as f:\n",
    "    model_cf = pickle.load(f)\n",
    "\n",
    "with open('/Users/anuj/Desktop/Recommender_G3P2/Collaborative/user2idx.pkl', 'rb') as f:\n",
    "    user2idx = pickle.load(f)\n",
    "\n",
    "with open('/Users/anuj/Desktop/Recommender_G3P2/Collaborative/news2idx.pkl', 'rb') as f:\n",
    "    news2idx = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4beafbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing training data: 100%|██████████| 156965/156965 [00:01<00:00, 90365.47it/s]\n"
     ]
    }
   ],
   "source": [
    "data = np.load(\"hybrid_data.npz\")\n",
    "X = data[\"X\"]\n",
    "y = data[\"y\"]\n",
    "with open(\"scaler.pkl\", \"rb\") as f:\n",
    "    scaler = pickle.load(f)\n",
    "news_stats = defaultdict(lambda: {'clicks': deque(), 'impressions': deque()})\n",
    "\n",
    "for row in tqdm(behaviors_train.itertuples(), total=len(behaviors_train), desc=\"Preparing training data\"):\n",
    "    uid = row.UserID\n",
    "    if uid not in user2idx:\n",
    "        continue\n",
    "    uid_idx = user2idx[uid]\n",
    "\n",
    "    impressions = row.Impressions.split()\n",
    "    for imp in impressions:\n",
    "        if '-' not in imp:\n",
    "            continue\n",
    "            \n",
    "        nid, label = imp.split('-')\n",
    "        label = int(label)\n",
    "        news_stats[nid]['impressions'].append(row.Timestamp)\n",
    "        if label == '1':\n",
    "            news_stats[nid]['clicks'].append(row.Timestamp)\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eed30bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting logistic regression...\n",
      "Trained Logistic Regression Coefficients: [[ 0.21275516  0.33858284 -0.0796488 ]] [-0.08261626]\n"
     ]
    }
   ],
   "source": [
    "# Train logistic regression\n",
    "print(\"Fitting logistic regression...\")\n",
    "logreg = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
    "logreg.fit(X, y)\n",
    "\n",
    "print(\"Trained Logistic Regression Coefficients:\", logreg.coef_, logreg.intercept_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "167f9b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating hybrid model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 73152/73152 [01:26<00:00, 842.58it/s] \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================\n",
    "# 5. Evaluate Hybrid Model\n",
    "# ============================\n",
    "print(\"Evaluating hybrid model...\")\n",
    "all_labels, all_scores = [], []\n",
    "\n",
    "def update_rolling_stats(current_time):\n",
    "    for nid in list(news_stats.keys()):\n",
    "        while news_stats[nid]['clicks'] and news_stats[nid]['clicks'][0] < current_time - TIME_WINDOW:\n",
    "            news_stats[nid]['clicks'].popleft()\n",
    "        while news_stats[nid]['impressions'] and news_stats[nid]['impressions'][0] < current_time - TIME_WINDOW:\n",
    "            news_stats[nid]['impressions'].popleft()\n",
    "        if not news_stats[nid]['clicks'] and not news_stats[nid]['impressions']:\n",
    "            del news_stats[nid]\n",
    "\n",
    "\n",
    "for row in tqdm(valid_behaviors.itertuples(), total=len(valid_behaviors), desc=\"Evaluating\"):\n",
    "    uid = row.UserID\n",
    "    if uid not in user2idx:\n",
    "        continue\n",
    "    uid_idx = user2idx[uid]\n",
    "    current_time = row.Timestamp\n",
    "    update_rolling_stats(current_time)\n",
    "    labels, scores = [], []\n",
    "\n",
    "    impressions = row.Impressions.split()\n",
    "    for imp in impressions:\n",
    "        if '-' not in imp:\n",
    "            continue\n",
    "            \n",
    "        nid, label = imp.split('-')\n",
    "        labels.append(int(label))\n",
    "\n",
    "        global_ctr = ctr_global.get(nid, 0.0)\n",
    "        time_ctr = time_aware_ctr.get(nid, 0.0)\n",
    "        score_ctr = ALPHA * time_ctr + (1 - ALPHA) * global_ctr        \n",
    "        if uid in user_profiles and nid in news_id_to_index:\n",
    "            user_vector = user_profiles[uid].reshape(1, -1)\n",
    "            news_vector = tfidf_matrix[news_id_to_index[nid]]\n",
    "            score_cbf = cosine_similarity(user_vector, news_vector)[0][0]\n",
    "        else:\n",
    "            score_cbf = 0.0\n",
    "        if nid in news2idx:\n",
    "            nid_idx = news2idx[nid]\n",
    "            score_cf = np.dot(model_cf.user_factors[uid_idx], model_cf.item_factors[nid_idx])\n",
    "        else:\n",
    "            score_cf = 0.0\n",
    "\n",
    "        features = np.array([score_ctr, score_cbf, score_cf]).reshape(1, -1)\n",
    "        prob = logreg.predict_proba(features)[0][1]  # Probability of click (class 1)\n",
    "        scores.append(prob)\n",
    "        news_stats[nid]['impressions'].append(current_time)\n",
    "        if label == '1':\n",
    "            news_stats[nid]['clicks'].append(current_time)\n",
    "\n",
    "    if scores and len(set(labels)) > 1:\n",
    "        all_labels.append(labels)\n",
    "        all_scores.append(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "048eea83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Hybrid Model Evaluation ---\n",
      "AUC: 0.6829\n",
      "MRR: 0.3900\n",
      "nDCG@5: 0.3755\n",
      "nDCG@10: 0.4329\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define evaluation metrics\n",
    "def mrr_score(labels, scores):\n",
    "    order = np.argsort(scores)[::-1]\n",
    "    labels = np.array(labels)[order]\n",
    "    for idx, label in enumerate(labels):\n",
    "        if label == 1:\n",
    "            return 1.0 / (idx + 1)\n",
    "    return 0.0\n",
    "\n",
    "def dcg_score(labels, scores, k):\n",
    "    order = np.argsort(scores)[::-1][:k]\n",
    "    gains = np.array(labels)[order]\n",
    "    discounts = np.log2(np.arange(2, len(gains) + 2))\n",
    "    return np.sum(gains / discounts)\n",
    "\n",
    "def ndcg_score(labels, scores, k):\n",
    "    dcg = dcg_score(labels, scores, k)\n",
    "    ideal_dcg = dcg_score(labels, labels, k)\n",
    "    return dcg / ideal_dcg if ideal_dcg > 0 else 0.0\n",
    "\n",
    "# Compute final metrics\n",
    "mrr, ndcg5, ndcg10, auc = [], [], [], []\n",
    "\n",
    "for labels, scores in zip(all_labels, all_scores):\n",
    "    if len(set(labels)) > 1:  # Need both positive and negative examples for AUC\n",
    "        auc.append(roc_auc_score(labels, scores))\n",
    "    mrr.append(mrr_score(labels, scores))\n",
    "    ndcg5.append(ndcg_score(labels, scores, 5))\n",
    "    ndcg10.append(ndcg_score(labels, scores, 10))\n",
    "\n",
    "print(\"\\n--- Hybrid Model Evaluation ---\")\n",
    "print(f\"AUC: {np.mean(auc):.4f}\")\n",
    "print(f\"MRR: {np.mean(mrr):.4f}\")\n",
    "print(f\"nDCG@5: {np.mean(ndcg5):.4f}\")\n",
    "print(f\"nDCG@10: {np.mean(ndcg10):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0789fd0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model components...\n",
      "Done! All components saved successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================\n",
    "# 6. Save trained components for future use\n",
    "# ============================\n",
    "print(\"Saving model components...\")\n",
    "\n",
    "# Save the logistic regression model\n",
    "with open('hybrid_logreg_model_1.pkl', 'wb') as f:\n",
    "    pickle.dump(logreg, f)\n",
    "\n",
    "print(\"Done! All components saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6d57b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
